{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-auth-oauthlib 1.0.0 requires google-auth>=2.15.0, but you have google-auth 1.4.2 which is incompatible.\n",
      "botocore 1.29.137 requires urllib3<1.27,>=1.25.4, but you have urllib3 1.24.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: awscli in c:\\users\\hazem\\appdata\\roaming\\python\\python310\\site-packages (1.27.137)\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in c:\\users\\hazem\\appdata\\roaming\\python\\python310\\site-packages (from awscli) (4.7.2)\n",
      "Requirement already satisfied: botocore==1.29.137 in c:\\users\\hazem\\appdata\\roaming\\python\\python310\\site-packages (from awscli) (1.29.137)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\hazem\\appdata\\roaming\\python\\python310\\site-packages (from awscli) (0.6.1)\n",
      "Requirement already satisfied: PyYAML<5.5,>=3.10 in c:\\users\\hazem\\appdata\\roaming\\python\\python310\\site-packages (from awscli) (5.4.1)\n",
      "Requirement already satisfied: docutils<0.17,>=0.10 in c:\\users\\hazem\\appdata\\roaming\\python\\python310\\site-packages (from awscli) (0.16)\n",
      "Requirement already satisfied: colorama<0.4.5,>=0.2.5 in c:\\users\\hazem\\appdata\\roaming\\python\\python310\\site-packages (from awscli) (0.4.4)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\hazem\\appdata\\roaming\\python\\python310\\site-packages (from botocore==1.29.137->awscli) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\hazem\\appdata\\roaming\\python\\python310\\site-packages (from botocore==1.29.137->awscli) (2.8.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\hazem\\appdata\\roaming\\python\\python310\\site-packages (from rsa<4.8,>=3.1.2->awscli) (0.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hazem\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.29.137->awscli) (1.12.0)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "Successfully installed urllib3-1.26.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "requests 2.21.0 requires urllib3<1.25,>=1.21.1, but you have urllib3 1.26.15 which is incompatible.\n",
      "google-auth-oauthlib 1.0.0 requires google-auth>=2.15.0, but you have google-auth 1.4.2 which is incompatible.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Initialize the libs and download the dataset\n",
    "!pip3 install mne -q\n",
    "!pip3 install awscli\n",
    "!aws s3 sync --no-sign-request s3://openneuro.org/ds003626 ds003626/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(23)\n",
    "\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "warnings.filterwarnings(action = \"ignore\", category = DeprecationWarning )\n",
    "warnings.filterwarnings(action = \"ignore\", category = FutureWarning )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The root dir\n",
    "root_dir = \"C:/Users/hazem/Downloads/ds003626\"\n",
    "\n",
    "# Sampling rate\n",
    "fs = 256\n",
    "\n",
    "# Select the useful par of each trial. Time in seconds\n",
    "t_start = 1.5\n",
    "t_end = 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from au.pre_process import get_subjects_data_and_label\n",
    "\n",
    "condition = \"Inner\"\n",
    "\n",
    "data, labels = get_subjects_data_and_label(root_dir, condition, t_start = t_start, t_end = t_end, fs = fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects 10\n",
      "Data shape: [trials x channels x samples]\n",
      "Shape (200, 128, 512)\n",
      "Labels\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of subjects\", len(data))\n",
    "print(\"Data shape: [trials x channels x samples]\")\n",
    "print(\"Shape\", data[0].shape) # Trials, channels, samples\n",
    "\n",
    "print(\"Labels\")\n",
    "print(len(labels)) # Time stamp, class , condition, session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2236, 128, 512) (2236,)\n"
     ]
    }
   ],
   "source": [
    "data_array=np.vstack(data)\n",
    "label_array=np.hstack(labels)\n",
    "print(data_array.shape, label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define all the features\n",
    "from scipy import stats\n",
    "\n",
    "def mean(x):\n",
    "    return np.mean(x, axis=-1)\n",
    "\n",
    "def std(x):\n",
    "    return np.std(x, axis=-1)\n",
    "\n",
    "def ptp(x):\n",
    "    return np.ptp(x, axis=-1)\n",
    "\n",
    "def var(x):\n",
    "    return np.var(x, axis=-1)\n",
    "\n",
    "def minim(x):\n",
    "    return np.min(x, axis=-1)\n",
    "\n",
    "def maxim(x):\n",
    "    return np.max(x, axis=-1)\n",
    "\n",
    "def argminim(x):\n",
    "    return np. argmin(x, axis=-1)\n",
    "\n",
    "def argmaxim(x):\n",
    "    return np.argmax(x,axis=-1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2, axis=-1))\n",
    "\n",
    "def abs_diff_signal(x):\n",
    "    return np.sum(np.abs(np.diff(x, axis=-1)), axis=-1)\n",
    "\n",
    "def skewness(x):\n",
    "    return stats.skew(x, axis=-1)\n",
    "\n",
    "def kurtosis(x):\n",
    "    return stats.kurtosis(x, axis=-1)\n",
    "\n",
    "def concatenate_features(x):\n",
    "    return np.concatenate((mean(x), std(x), ptp(x), var(x), minim(x), maxim(x), argminim(x),\n",
    "                          argmaxim(x), rms(x), abs_diff_signal(x), skewness(x), kurtosis(x)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features=[]\n",
    "for d in data_array:\n",
    "    features.append(concatenate_features(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2236, 1536)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array=np.array(features)\n",
    "features_array.shape # 1536 / 128 = 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, roc_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# This section contains the function to support the model evaluation\n",
    "\n",
    "\n",
    "def run_cross_validation(classifier, x_tr, y_tr):\n",
    "    k_fold = model_selection.KFold(n_splits=10)\n",
    "    results = model_selection.cross_val_score(classifier, x_tr, y_tr, cv=k_fold, scoring='accuracy')\n",
    "    print('{:<50} {:.4f}'.format(\"Cross validation average accuracy with 10-fold:\", (results.mean())))\n",
    "\n",
    "def run_accuracy(y_tst, y_p):\n",
    "    print('{:<50} {:.4f}'.format(\"Accuracy\", (metrics.accuracy_score(y_tst, y_p))))\n",
    "\n",
    "def plot_confusion_matrix(y_tst, y_pred, y_labels):\n",
    "    lbs = y_labels.unique()\n",
    "    confusion_matrix = metrics.confusion_matrix(y_tst, y_pred)\n",
    "    matrix_df = pd.DataFrame(confusion_matrix)\n",
    "    ax = plt.axes()\n",
    "    sns.set(font_scale=1.3)\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(matrix_df, annot=True, fmt=\"g\", ax=ax, cmap=\"magma\")\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xlabel(\"Predicted label\", fontsize =15)\n",
    "    ax.set_ylabel(\"True Label\", fontsize=15)\n",
    "    ax.set_yticklabels(list(lbs), rotation = 0)\n",
    "    plt.show()\n",
    "\n",
    "# Extract importance\n",
    "def print_importance(classifier, x_tr):\n",
    "    importance = pd.DataFrame({'feature': x_tr.columns, 'importance' : np.round(classifier.feature_importances_, 3)})\n",
    "    importance.sort_values('importance', ascending=False, inplace = True)\n",
    "    print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy                                           0.2668\n",
      "Cross validation average accuracy with 10-fold:    0.2441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.21      0.23       183\n",
      "           1       0.32      0.32      0.32       169\n",
      "           2       0.23      0.30      0.26       156\n",
      "           3       0.26      0.25      0.25       163\n",
      "\n",
      "    accuracy                           0.27       671\n",
      "   macro avg       0.27      0.27      0.27       671\n",
      "weighted avg       0.27      0.27      0.27       671\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hazem\\Documents\\clinical decision final project\\classification-checkpoint.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hazem/Documents/clinical%20decision%20final%20project/classification-checkpoint.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hazem/Documents/clinical%20decision%20final%20project/classification-checkpoint.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     evaluate_model(clf, x_train, x_test, y_train, y_test)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hazem/Documents/clinical%20decision%20final%20project/classification-checkpoint.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m run_random_forest()\n",
      "\u001b[1;32mc:\\Users\\hazem\\Documents\\clinical decision final project\\classification-checkpoint.ipynb Cell 11\u001b[0m in \u001b[0;36mrun_random_forest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hazem/Documents/clinical%20decision%20final%20project/classification-checkpoint.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m run_cross_validation(clf, x_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hazem/Documents/clinical%20decision%20final%20project/classification-checkpoint.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hazem/Documents/clinical%20decision%20final%20project/classification-checkpoint.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m evaluate_model(clf, x_train, x_test, y_train, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def run_random_forest():\n",
    "    print(\"Random Forest\")\n",
    "    # Split dataset into training set and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features_array, label_array, test_size=0.30) # 70% test and 30% training\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    run_accuracy(y_test, y_pred)\n",
    "    run_cross_validation(clf, x_train, y_train)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    # evaluate_model(clf, x_train, x_test, y_train, y_test)\n",
    "\n",
    "run_random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network\n",
      "Accuracy                                           0.2277\n",
      "Cross validation average accuracy with 10-fold:    0.2388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       137\n",
      "           1       0.00      0.00      0.00       103\n",
      "           2       0.00      0.00      0.00       106\n",
      "           3       0.23      1.00      0.37       102\n",
      "\n",
      "    accuracy                           0.23       448\n",
      "   macro avg       0.06      0.25      0.09       448\n",
      "weighted avg       0.05      0.23      0.08       448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hazem\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hazem\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hazem\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def run_neural_network():\n",
    "    print(\"Neural Network\")\n",
    "    # Split dataset into training set and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features_array, label_array, test_size=0.20) # 80% test and 20% training\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    run_accuracy(y_test, y_pred)\n",
    "    run_cross_validation(clf, x_train, y_train)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    #plot_confusion_matrix(y_test, y_pred, label_array)\n",
    "\n",
    "run_neural_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy                                           0.1964\n",
      "Cross validation average accuracy with 10-fold:    0.2075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.12      0.15       112\n",
      "           1       0.32      0.17      0.22       134\n",
      "           2       0.19      0.25      0.22       102\n",
      "           3       0.16      0.26      0.20       100\n",
      "\n",
      "    accuracy                           0.20       448\n",
      "   macro avg       0.21      0.20      0.19       448\n",
      "weighted avg       0.22      0.20      0.20       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiclass Random Forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def run_random_forest_multi_class():\n",
    "    print(\"Random Forest\")\n",
    "    # Split dataset into training set and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features_array, label_array, test_size=0.20) # 80% test and 20% training\n",
    "    rf = RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 200, max_depth=8, criterion='gini')\n",
    "    clf = OneVsRestClassifier(rf)\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    run_accuracy(y_test, y_pred)\n",
    "    run_cross_validation(clf, x_train, y_train)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    #print_importance(clf, x_train)\n",
    "    #plot_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "run_random_forest_multi_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy                                           0.2388\n",
      "Cross validation average accuracy with 10-fold:    0.2372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.28      0.28       114\n",
      "           1       0.22      0.27      0.25       103\n",
      "           2       0.22      0.17      0.19       121\n",
      "           3       0.23      0.25      0.24       110\n",
      "\n",
      "    accuracy                           0.24       448\n",
      "   macro avg       0.24      0.24      0.24       448\n",
      "weighted avg       0.24      0.24      0.24       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def run_random_forest(X, y):\n",
    "    print(\"Random Forest\")\n",
    "    # Split dataset into training set and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20) # 80% test and 20% training\n",
    "    clf = RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 200, max_depth=8, criterion='gini')\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    run_accuracy(y_test, y_pred)\n",
    "    run_cross_validation(clf, x_train, y_train)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    #print_importance(clf, x_train)\n",
    "    #plot_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "run_random_forest(features_array, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hazem\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hazem\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hazem\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hazem\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                           0.2444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hazem\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def run_linear_svc_multi_class():\n",
    "    print(\"Linear SVC\")\n",
    "    # Split dataset into training set and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features_array, label_array, test_size=0.30) # 70% test and 30% training\n",
    "    rf = LinearSVC(random_state=0, max_iter=10000)\n",
    "    clf = OneVsRestClassifier(rf)\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    run_accuracy(y_test, y_pred)\n",
    "    run_cross_validation(clf, x_train, y_train)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "run_linear_svc_multi_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
